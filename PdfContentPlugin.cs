using Microsoft.SemanticKernel;
using PdfReader;
using System.ComponentModel;
using UglyToad.PdfPig.Graphics;


namespace PDF_Llama;

internal class PdfContentPlugin
{

    const string PDFPath = @"PDFs/";
    const string PDFFileName = @"VN";

    // The Kernel is automatically injected into the plugin methods if they require it.
    // This allows the plugin to use the kernel's configured AI services.

    /// <summary>
    /// Read PDF chunks and uses the kernel to summarize them.
    /// </summary>
    /// <param name="kernel">The Semantic Kernel instance (injected automatically).</param>
    /// <param name="filePath">The path to the text file to be summarized.</param>
    /// <returns>A summary of the file content generated by the LLM.</returns>
    [KernelFunction("SummarizeFile")]
[Description("Reads a text file and generates a summary of its content using an AI model.")]
public async Task<string> SummarizeFile(
    Kernel kernel, 
    [Description("The full path to the text file to summarize.")] string pdfFileName)
    {

        string pdfpath = "";
        List<string>? json_chunks = null; 
        try
        {
            Reader reader = new Reader(PDFPath);
            pdfpath = PDFPath + pdfFileName;
            string filePath = Path.GetFullPath(pdfpath);

            json_chunks = reader.ReadPdfBlocks(pdfpath);

        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error reading file {pdfpath}: {ex.Message}");
            return $"Error reading file {pdfpath}: {ex.Message}";
        }

        // https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/GettingStartedWithTextSearch/InMemoryVectorStoreFixture.cs#L139


        // Create a prompt for the AI model.Instruct the model to summarize the provided text.
        var prompt = @$"Summarize the following text concisely and accurately.
            If the text is too short or doesn't contain meaningful information, state that.

            Text to summarize:
            {json_chunks?[0]}

            Summary:";

        Console.WriteLine("Sending content to Ollama for summarization...");

        try
        {
            // Invoke Ollama text generation service with the prompt.
            var result = await kernel.InvokePromptAsync(prompt);

            // Extract and return the generated summary.
            return result.GetValue<string>()?.Trim() ?? "No summary generated.";
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error invoking AI for summarization: {ex.Message}");
            Console.WriteLine("Please ensure Ollama is running and the specified model is downloaded.");
            return $"Error invoking AI for summarization: {ex.Message}";
        }


    }

}

